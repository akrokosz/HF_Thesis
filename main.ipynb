{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from collections import defaultdict\n",
    "import warnings\n",
    "from sys import stderr\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import stock_indicators as sa\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import pandas as pd\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "import yfinance as yf\n",
    "from stock_indicators import Quote\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "funds_w_names = defaultdict(pd.DataFrame)",
   "id": "8b5f927888bbca93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "etf_names = ['IE0005042456', 'EDMU.SW', 'EDG2.L', '36BA.DE', 'CBUS.DE', 'EWSA.AS','IE00B0M62X26','IE00B14X4Q57','IE00B1XNHC34','IE00B3FH7618','IE00B3ZW0K18','IE00B52MJY50','IE00B52VJ196','IE00B5M4WH52','IE00B66F4759','IE00B9M6RS56','IE00BD8PGZ49','IE00BDFK1573','IE00BDZVH966','IE00BFNM3G45','IE00BGPP6697','IE00BHZPJ015','IE00BHZPJ452','IE00BHZPJ783',\n",
    "'IE00BLDGH553','IE00BMDFDY08','IE00BMG6Z448','IE00BYYHSM20','IE00BYZTVT56','IE00BZ173V67','IE00BZ1NCS44']"
   ],
   "id": "b944a9f1b9c7474",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(etf_names)",
   "id": "d2b08b50ebc48eff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T15:27:39.288598Z",
     "start_time": "2024-12-07T15:27:36.561298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fund in etf_names:\n",
    "    try:\n",
    "        a = (pd.DataFrame(yf.Ticker(fund).history(start=\"2023-01-01\", end=\"2024-01-01\")))\n",
    "    except:\n",
    "        print(fund)\n",
    "    a.index = pd.to_datetime(a.index)\n",
    "    a.index = a.index.normalize()\n",
    "    full_date_range = pd.date_range(start=a.index.min(), end=a.index.max(), freq=\"D\")\n",
    "    a = a.reindex(full_date_range)\n",
    "    a.fillna(method=\"bfill\", inplace=True)\n",
    "    a.drop([\"Dividends\", \"Stock Splits\", \"Capital Gains\"], inplace=True, axis=1)\n",
    "    funds_w_names[fund] = a"
   ],
   "id": "50bc1e8853731259",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not get exchangeTimezoneName for ticker '' reason: 'chart'\n",
      "$: possibly delisted; no timezone found\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Neither `start` nor `end` can be NaT",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[53], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m a\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(a\u001B[38;5;241m.\u001B[39mindex)\n\u001B[0;32m      7\u001B[0m a\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m a\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mnormalize()\n\u001B[1;32m----> 8\u001B[0m full_date_range \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdate_range\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfreq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mD\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m a \u001B[38;5;241m=\u001B[39m a\u001B[38;5;241m.\u001B[39mreindex(full_date_range)\n\u001B[0;32m     10\u001B[0m a\u001B[38;5;241m.\u001B[39mfillna(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbfill\u001B[39m\u001B[38;5;124m\"\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\DataspellProjects\\HF_Thesis\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:1008\u001B[0m, in \u001B[0;36mdate_range\u001B[1;34m(start, end, periods, freq, tz, normalize, name, inclusive, unit, **kwargs)\u001B[0m\n\u001B[0;32m   1005\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m freq \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m com\u001B[38;5;241m.\u001B[39many_none(periods, start, end):\n\u001B[0;32m   1006\u001B[0m     freq \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mD\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1008\u001B[0m dtarr \u001B[38;5;241m=\u001B[39m \u001B[43mDatetimeArray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_range\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1009\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1010\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1011\u001B[0m \u001B[43m    \u001B[49m\u001B[43mperiods\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mperiods\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1012\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfreq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfreq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1013\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtz\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1014\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnormalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclusive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclusive\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43munit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1018\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1019\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatetimeIndex\u001B[38;5;241m.\u001B[39m_simple_new(dtarr, name\u001B[38;5;241m=\u001B[39mname)\n",
      "File \u001B[1;32m~\\DataspellProjects\\HF_Thesis\\venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:430\u001B[0m, in \u001B[0;36mDatetimeArray._generate_range\u001B[1;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive, unit)\u001B[0m\n\u001B[0;32m    427\u001B[0m     end \u001B[38;5;241m=\u001B[39m Timestamp(end)\n\u001B[0;32m    429\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m start \u001B[38;5;129;01mis\u001B[39;00m NaT \u001B[38;5;129;01mor\u001B[39;00m end \u001B[38;5;129;01mis\u001B[39;00m NaT:\n\u001B[1;32m--> 430\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNeither `start` nor `end` can be NaT\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    432\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m unit \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    433\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m unit \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mms\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mus\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mns\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "\u001B[1;31mValueError\u001B[0m: Neither `start` nor `end` can be NaT"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def portfolio_factory(etfs: list):\n",
    "    giga_fund = pd.DataFrame()\n",
    "    c = 0\n",
    "    for f in etfs:\n",
    "        f.index = pd.to_datetime(f.index)  # ensure index is datetime if not already\n",
    "        f[\"time_idx\"] = (f.index.date - f.index.date[0]).astype(\"timedelta64[D]\").astype(int)\n",
    "        f['group_id'] = c\n",
    "        \n",
    "        giga_fund = pd.concat([giga_fund, f])\n",
    "        c+= 1\n",
    "    return giga_fund"
   ],
   "id": "c12ed0a90126cbaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def technical_indicators_factory(etfs: list, names: list):\n",
    "    indicators_per_fund = defaultdict(pd.DataFrame)\n",
    "    figs = []\n",
    "\n",
    "    for id, f in enumerate(etfs):\n",
    "\n",
    "        quotes_for_f = [\n",
    "            Quote(\n",
    "                date=row.Index,\n",
    "                open=row.Open,\n",
    "                high=row.High,\n",
    "                low=row.Low,\n",
    "                close=row.Close,\n",
    "                volume=row.Volume\n",
    "            )\n",
    "            for row in IE.itertuples()]\n",
    "\n",
    "        ema_for_f = sa.indicators.get_ema(quotes_for_f, 9)\n",
    "        valid_ema_for_f = [\n",
    "            (result.date, result.ema)\n",
    "            for result in ema_for_f\n",
    "            if result.ema is not None\n",
    "        ]\n",
    "        ema_dates, ema_values = zip(*valid_ema_for_f)\n",
    "\n",
    "        vwma_for_f = sa.indicators.get_vwma(quotes=quotes_for_f, lookback_periods=20)\n",
    "        valid_vwma_for_f = [\n",
    "            (result.date, result.vwma)\n",
    "            for result in vwma_for_f\n",
    "            if result.vwma is not None\n",
    "        ]\n",
    "        vwma_dates, vwma_values = zip(*valid_vwma_for_f)\n",
    "\n",
    "        macd_for_f = sa.indicators.get_macd(quotes=quotes_for_f)\n",
    "        valid_macd_for_f = [\n",
    "            (result.date, result.macd, result.signal, result.histogram)\n",
    "            for result in macd_for_f\n",
    "            if result.macd is not None and result.signal is not None and result.histogram is not None\n",
    "        ]\n",
    "        macd_dates, macd_values, macd_signal, macd_histogram = zip(*valid_macd_for_f)\n",
    "\n",
    "        stoch_for_f = sa.indicators.get_stoch(quotes=quotes_for_f)\n",
    "        valid_stoch_for_f = [\n",
    "            (result.date, result.oscillator, result.signal, result.percent_j)\n",
    "            for result in stoch_for_f\n",
    "            if result.date is not None and result.oscillator is not None and result.signal is not None\n",
    "        ]\n",
    "        stoch_dates, stoch_oscillator, stoch_signal, stoch_percent_j  = zip(*valid_stoch_for_f)\n",
    "\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(12,6))\n",
    "        axes[0].plot(ema_dates[-20:], ema_values[-20:], label='EMA', linewidth=2)\n",
    "        axes[0].plot(ema_dates[-20:], f['Close'][-20:], label='Close', linewidth=2)\n",
    "        axes[0].legend(loc='best')\n",
    "\n",
    "        axes[1].plot(vwma_dates[-20:], vwma_values[-20:], label='VWMA', linewidth=2)\n",
    "        axes[1].plot(vwma_dates[-20:], f['Close'][-20:], label='Close', linewidth=2)\n",
    "        axes[1].legend(loc='best')\n",
    "\n",
    "        axes[2].plot(macd_dates[-20:], macd_values[-20:], label='MACD', linewidth=2)\n",
    "        axes[2].plot(macd_dates[-20:], macd_signal[-20:], label='Signal', linewidth=2)\n",
    "        axes[2].legend(loc='best')\n",
    "\n",
    "        axes[3].plot(stoch_dates[-20:], stoch_oscillator[-20:], label='STOCH OSCILLATOR', linewidth=2)\n",
    "        axes[3].plot(stoch_dates[-20:], stoch_percent_j[-20:], label='%J', linewidth=2)\n",
    "        axes[3].plot(stoch_dates[-20:], stoch_signal[-20:], label='Signal', linewidth=2)\n",
    "        axes[3].legend(loc='best')\n",
    "\n",
    "        f['EMA'] = [x.ema for x in ema_for_f]\n",
    "        f['MACD'] = [x.macd for x in macd_for_f]\n",
    "        f['VWMA'] = [x.vwma for x in vwma_for_f]\n",
    "        f['STOCH_OSCILLATOR'] = [x.oscillator for x in stoch_for_f]\n",
    "        figs.append(fig)\n",
    "\n",
    "        indicators_per_fund[names[id]]= f\n",
    "    return indicators_per_fund, figs"
   ],
   "id": "d8c6c4447cb05888",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fit_predict(training_cutoff_idx: pd.Timestamp, epochs: int, batch_size: int, lr: float, dropout: float, df: pd.DataFrame, independent_variables: list):\n",
    "    training = TimeSeriesDataSet(\n",
    "        df[lambda x: x.time_idx <= training_cutoff_idx],  # Use the determined cutoff index\n",
    "        time_idx=\"time_idx\",                             # Sequential time index\n",
    "        target=\"Close\",                                  # Target variable\n",
    "        group_ids=[\"group_id\"],                          # Group identifier\n",
    "        min_encoder_length=365 // 2,      # Minimum input sequence length\n",
    "        max_encoder_length=365,           # Maximum input sequence length\n",
    "        min_prediction_length=1,                         # Minimum forecast length\n",
    "        max_prediction_length=7,     # Maximum forecast length (31 for December)\n",
    "        static_reals=[],                                 # No static real variables\n",
    "        time_varying_known_reals= independent_variables,  # Known inputs\n",
    "        time_varying_unknown_reals=[\"Close\"],            # Target variable\n",
    "        target_normalizer=GroupNormalizer(groups=[\"group_id\"], transformation=\"softplus\"),\n",
    "        add_relative_time_idx=True,                      # Add relative time index\n",
    "        add_target_scales=True,                               # Scale the target variable\n",
    "        add_encoder_length=True,                          # Include encoder length feature\n",
    "        allow_missing_timesteps=False,                   # Ensure no missing steps\n",
    "    )\n",
    "\n",
    "    validation = TimeSeriesDataSet.from_dataset(\n",
    "        training,\n",
    "        df,\n",
    "        predict=True,\n",
    "        stop_randomization=True                             # Ensures no randomization in validation dataset\n",
    "    )\n",
    "\n",
    "    batch_size = batch_size\n",
    "\n",
    "    train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "    tft = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        learning_rate=lr,              # Learning rate\n",
    "        hidden_size=16,                  # Model hidden size\n",
    "        attention_head_size=1,           # Number of attention heads\n",
    "        dropout=dropout,                     # Dropout rate\n",
    "        hidden_continuous_size=8,        # Hidden size for continuous variables\n",
    "        output_size=7,                   # Output quantiles (e.g., 10th to 90th percentile)\n",
    "        loss=QuantileLoss(),             # Loss function\n",
    "        log_interval=10,                 # Log every 10 batches\n",
    "        reduce_on_plateau_patience=4,    # Reduce learning rate on plateau\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"checkpoints/\",\n",
    "        filename=\"tft-model-{epoch:02d}-{val_loss:.2f}\",\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\",  # \n",
    "        mode=\"min\",  # minimize validation loss\n",
    "    )\n",
    "\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=4, verbose=False, mode=\"min\")\n",
    "    lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "    logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        # logger=logger,\n",
    "        max_epochs=epochs,\n",
    "        accelerator='cuda',\n",
    "        devices=\"auto\",\n",
    "        gradient_clip_val=0.1,\n",
    "        callbacks=[early_stop_callback, lr_logger, checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(tft, train_dataloader, val_dataloader)\n",
    "    raw_predictions = tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "    predicted_median_np = raw_predictions.output.prediction[0, :, 1].detach().cpu().numpy()\n",
    "    return predicted_median_np"
   ],
   "id": "d4e0139038771bea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def metrics_and_plt(df: pd.DataFrame, preds:list, date_range:pd.date_range):\n",
    "    actual_values = df[\"Close\"][\"2023-12-23\":]\n",
    "    mse = mean_squared_error(actual_values, preds)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(date_range, actual_values, marker=\"x\", label=\"Actual Close\", color=\"orange\")\n",
    "    plt.plot(date_range, preds, marker=\"o\", label=\"Predicted Median\")\n",
    "    plt.title(\"Predicted Values for December 23 to December 29, 2023\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Predicted Value\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return mse, plt"
   ],
   "id": "c6594be45b64f802",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NO INDICATORS, ONE ETF",
   "id": "374c77154a552cf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#IE00B52MJY50\n",
    "IE = portfolio_factory(etfs=[funds_w_names['IE00B52MJY50']])"
   ],
   "id": "7015cf2c85922a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_cutoff_date = pd.to_datetime(\"2023-12-22 00:00:00+01:00\").tz_convert(\"Europe/London\")\n",
    "training_cutoff_idx = IE.loc[training_cutoff_date, \"time_idx\"]"
   ],
   "id": "23caf125363f670f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "IE_preds = fit_predict(training_cutoff_idx=training_cutoff_idx, epochs=12, batch_size=128, lr=1e-3, dropout=0.1, df=IE, independent_variables=[\"Open\", \"High\", \"Low\", \"Volume\"])",
   "id": "70aa8fbc912542dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "IE_mse, IE_plt = metrics_and_plt(IE, IE_preds, pd.date_range(start=\"2023-12-23\", end=\"2023-12-29\"))",
   "id": "108ff9957e21c8ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ADDING INDICATORS",
   "id": "114f4f5e54e524bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "IE_indicators, IE_indicators_plt1 = technical_indicators_factory([funds_w_names['IE00B52MJY50']], ['IE00B52MJY50'])",
   "id": "680751c0b685d109",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "IE_preds = fit_predict(training_cutoff_idx=training_cutoff_idx, epochs=120, batch_size=128, lr=1e-4, dropout=0.1, df=IE, independent_variables=[\"Open\", \"High\", \"Low\", \"Volume\", \"EMA\", \"VWMA\", \"MACD\", \"STOCH_OSCILLATOR\"])",
   "id": "a1643538bf79fa9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "IE_indicators_mse, IE_indicators_plt2= metrics_and_plt(IE_preds, pd.date_range(start=\"2023-12-23\", end=\"2023-12-29\"))",
   "id": "c30a473642a9d108",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "FULL HEDGE PORTFOLIO",
   "id": "8f04cc76a0903dfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "IE_indicators, IE_indicators_plt1 = technical_indicators_factory([funds_w_names['IE00B52MJY50']], ['IE00B52MJY50'])",
   "id": "1ee2040d5b29f00f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "GIGAFUND, GIGAFUND_MIN_IND = portfolio_factory(etfs=funds_w_names.values())",
   "id": "87350a53d892b2d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b188850e9fbe4c41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e7e58c48300d09d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "226abf95f64e9cd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def volatility_dataset_factory(funds):\n",
    "    log_returns = defaultdict(pd.DataFrame)\n",
    "    for k, v in funds.items():\n",
    "        print(f\"{k}:\")\n",
    "        funds[k][\"Return\"] = funds[k][\"Close\"].pct_change()\n",
    "        log_returns[k] = np.log(1+funds[k][\"Return\"])\n",
    "        log_returns[k].fillna(value=0, inplace=True)\n",
    "        funds[k][\"Rolling Volatility\"] = funds[k][\"Return\"].rolling(7).std()\n",
    "        funds[k].fillna(method=\"bfill\", inplace=True)"
   ],
   "id": "1c7093102449c3e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Monte Carlo",
   "id": "897d3b4d33f6cf0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calc_drift(funds):\n",
    "    drift_dict={}\n",
    "    for k, v in funds.items():\n",
    "        avg_pdr = funds[k].mean()\n",
    "        var = funds[k].var()\n",
    "        drift = avg_pdr-(.5*var)\n",
    "        drift_dict[k]=drift\n",
    "    return drift_dict"
   ],
   "id": "34be51388d9a0935",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def monte_carlo_sim(funds):\n",
    "    price_paths={}\n",
    "    for k, v in funds.items():\n",
    "        stdev=log_returns[k].std()\n",
    "        days=362\n",
    "        trials=100\n",
    "        Z = norm.ppf(np.random.rand(days,trials))\n",
    "        daily_returns=np.exp(np.array(drifts[k]) + np.array(stdev) * Z)\n",
    "        price_paths[k] = np.zeros_like(daily_returns)\n",
    "        price_paths[k][0] = funds[k][\"Close\"].iloc[-1]\n",
    "        for i in range(1,days):\n",
    "            price_paths[k][i] = price_paths[k][i-1] * daily_returns[i-1]\n",
    "    return price_paths"
   ],
   "id": "fd9ef7227fa0371a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pp=monte_carlo_sim(funds_w_names)",
   "id": "243a6cbe14e6600a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(pp[\"EWSA.AS\"])"
   ],
   "id": "4b9c2da0929b1ee5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "63d0db2dd0be907"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CHOLESKY MONTE CARLO",
   "id": "21244e2a26517f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T15:25:19.370960Z",
     "start_time": "2024-12-07T15:25:19.335944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "closes = dict.fromkeys(funds_w_names.keys())\n",
    "covs_means = []\n",
    "for k,v in funds_w_names.items():\n",
    "    closes[k] = v[\"Close\"]\n",
    "closes = pd.DataFrame(closes)\n",
    "r = closes.pct_change()\n",
    "covariance_matrix = r.cov()\n",
    "mean_returns = r.mean()"
   ],
   "id": "472946a13310e42a",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Close'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m covs_means \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k,v \u001B[38;5;129;01min\u001B[39;00m funds_w_names\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m----> 4\u001B[0m     closes[k] \u001B[38;5;241m=\u001B[39m \u001B[43mv\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mClose\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      5\u001B[0m closes \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(closes)\n\u001B[0;32m      6\u001B[0m r \u001B[38;5;241m=\u001B[39m closes\u001B[38;5;241m.\u001B[39mpct_change()\n",
      "File \u001B[1;32m~\\DataspellProjects\\HF_Thesis\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\DataspellProjects\\HF_Thesis\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    415\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Hashable):\n\u001B[1;32m--> 417\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Close'"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T15:18:01.573863Z",
     "start_time": "2024-12-07T15:18:01.550176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not np.all(np.linalg.eigvals(covariance_matrix) > 0):  # Eigenvalues must be positive\n",
    "    print(\"Covariance matrix not positive definite. Adding regularization.\")\n",
    "    covariance_matrix += np.eye(covariance_matrix.shape[0]) * 1e-6"
   ],
   "id": "39fa06a94fc0c250",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'covariance_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39meigvals(\u001B[43mcovariance_matrix\u001B[49m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m):  \u001B[38;5;66;03m# Eigenvalues must be positive\u001B[39;00m\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCovariance matrix not positive definite. Adding regularization.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m     covariance_matrix \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39meye(covariance_matrix\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1e-6\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'covariance_matrix' is not defined"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#to be filled with real data\n",
    "portfolio_weights = np.random.random(len(funds_w_names.keys())) # distribution of etfs in portfolio\n",
    "portfolio_weights /= np.sum(portfolio_weights)"
   ],
   "id": "f8f77bc00e9e2eb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "days = 60\n",
    "simulations = 100\n",
    "initial_port = 10000 # initial portfolio value\n",
    "portfolio_sims = np.full(shape=(days, simulations), fill_value=0.0) # default\n",
    "mean_matrix = np.full(shape=(days, len(portfolio_weights)), fill_value=mean_returns) # days x all etfs"
   ],
   "id": "cbba301e54614de2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for s in range(simulations):\n",
    "    Z = np.random.normal(size=(days, len(portfolio_weights)))\n",
    "    L = np.linalg.cholesky(covariance_matrix)\n",
    "    daily_returns = mean_matrix + np.inner(L, Z)\n",
    "    portfolio_sims[:, s] = np.cumprod(np.inner(portfolio_weights, daily_returns.T)+1)*initial_port\n",
    "        \n",
    "plt.plot(portfolio_sims)\n",
    "plt.ylabel(\"Portfolio Simulations\")"
   ],
   "id": "c81530a75c483afb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "covariance_matrix",
   "id": "d1ae11418fd1d0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d8429488a16b8599",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
